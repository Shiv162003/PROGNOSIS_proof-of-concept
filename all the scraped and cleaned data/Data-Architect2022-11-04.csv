company,role,salary,experience,Location,description,skills,qualification,industry_type,Functional_area,Employment_type,Role_category
"A Silicon-Valley headquartered company, Infogain is a global business oriented IT consulting provider of front-end, customer-facing technologies, processes and applications, leading to a more efficient and streamlined customer experience. We want our clients€™ interactions with their customers to be fast, efficient, and cost effective.With close to 4,000 employees in the United States, India, the Middle East, U.K., Singapore and Malaysia, we service 5 of the world€™s largest 50 companies, and 24 of the Fortune 500. we have million-dollar engagements with over 25 customers, many of which have been with us for 5 years or more.At Infogain, we place a high value on establishing long-term relationships with our clients, ultimately becoming virtual extensions of their organizations. In fact, more than 90% of our medium and large deal size clients from five years ago remain clients today. Why? Our consultants, project managers and engineering teams listen and address our clients€™ specific requirements with best-in-class solutions across a broad spectrum of service areas.Infogain is an Oracle Knowledge Management Expert, having the world€™s largest practice to improve customer support operations and boost satisfaction in High Tech, Insurance, Travel & Hospitality and Retail.We are also a global leader in Oracle Retail€™s customer facing products.For insurance companies, Infogain helps make the claims process more efficient, effective and customer friendly.","RoleData Engineer,",Not Disclosed,8 - 11 years,Noida,"Job descriptionGreeting form Infogain! We are having Immediate requirement for Azure Data Architect in Infogain India Pvt Ltd. Please Find the Job Description below & If you are interested please share your updated Resume with details:-Mode of Hiring-PermanentExperince-8-12 YrsSkills Required- ADF, SQL, MS SQL Server, SynapseNotice Period- Immediate to 30 Days MaxLocation- Noida/Bangalore/Pune/Mumbai (Currently work from home)Job Description 6+ Years experience in Azure Stack(ADF, ADLS, Synapse, Databricks, PowerBI) and strong Data Warehouse, SQL DB, Data Modelling Skills. Hands-on exposure to coding and mentor team on technical abilities Kindly share your update word formatted /pdf profile with the details below on arti.sharma@infogain.com Total exp-Exp in ADFExp in SynapseExp in DatabricksCurrent CTC:Exp CTC:NP -Current Location-Preferred Location- About Infogain:Infogain is a Silicon Valley headquartered company with expertise in software platform engineering and deep domain skills in travel, retail, insurance, automotive, and high technology. We accelerate the delivery of digital customer engagement systems using digital technologies such as cloud, microservices, robotic process automation, and artificial intelligence for our clients. Our unique engagement approach of Listen-Curate-Deliver helps to accelerate the innovation journey of 5 of the worlds largest 50 companies and 24 of the Fortune 500, with several relationships of over 10 years. We deliver positive business outcomes using rapid prototyping and a solid foundation of DevOps-based software platform engineering that ensure high-quality and on-time delivery. Our 3,500 global employees across the US, UK, Singapore, Middle East and India focus on client value creation, delivery excellence and innovation. Our locations in India have 2700 employees spanning Noida, Pune, Mumbai and Bangalore.Infogain maintains both strategic and technology partnerships with leading enterprise software providers to deliver value-added solutions. We engage with the world's largest, as well as mid-size, and startup, software providers for building product capability, product marketing, customization, professional services and post-implementation supportRoleData Engineer,Industry TypeIT Services & Consulting,Functional AreaData Science & Analytics,Employment TypeFull Time, PermanentRole CategoryData Science & Machine LearningEducationUG :Any GraduatePG :Any PostgraduateDoctorate :Any DoctorateKey SkillsAzure Data FactoryADFSkills highlighted with ‘‘ are preferred keyskills","['Azure Data Factory', 'ADF']","['UG :Any Graduate', 'PG :Any Postgraduate', 'Doctorate :Any Doctorate']","Industry TypeIT Services & Consulting,","Functional AreaData Science & Analytics,","Employment TypeFull Time, Permanent",Role CategoryData Science & Machine Learning
"Triangle ( A Unit of Ratein Infotech India Private Ltd) is a Recruitment Specialist Organisation with focus on Information Technology Industry. Incorporated in August 2000 with 4 offices in India at Mumbai, Pune, New Delhi & Bangalore, Triangle caters to more than 25 active clients who are Fortune 500 organizations and world¢??s largest IT organizations.  Our Core expertise is in End to End Permanent and Contract Staffing and Extended Services.  We have been Internationally recognized as WeConnect Certified woman owned and managed organization.  Triangle has featured in CIO Review Magazine as ¢??Company of the Year in Staffing and Recruitment¢? Category for year 2014.","RoleSolution Architect,",Not Disclosed,10 - 15 years,Bangalore/Bengaluru,"Job description   Experience in architecting with AWS or Azure Cloud Data Platform Successfully implemented large-scale data warehouse / data lake solutions in snowflake or AWS Redshift Be proficient in Data modelling and data architecture design experienced in reviewing 3rd Normal Form and Dimensional models    Experience in implementing Master data management, process design and implementation    Experience in implementing Data quality solutions including processes    Experience in IOT Design using AWS or Azure Cloud platforms    Experience designing and implementing machine learning solutions as part of high-volume data ingestion and transformation    Experience working with structured and unstructured data including geo-spatial data    Experience in technologies like python, SQL, no SQL, KAFKA, Elastic Search Hands on experience using snowflake, informatica, azure logic apps, azure functions, azure storage, azure data lake and azure search    Behaviors Required: Driven by our values and purpose in everything we do Visible, active, hands on approach to help teams be successful Strong proactive planning ability    Optimistic, energetic, problem solver, ability to see long term business outcomes    Collaborative, ability to listen, compromise to make progress    Stronger together mindset, with a focus on innovation & creation of tangible / realized value      Education      Qualifications, Accreditation, Training: Required: Degree in Computer Science and/or related fields Azure or AWS Solution Architecture certifications    RoleSolution Architect,Industry TypeRecruitment / Staffing,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsComputer scienceSolution architectureProcess designMachine learningData ArchitectData qualityInformaticaSQLPythonData architecture","['Computer science', 'Solution architecture', 'Process design', 'Machine learning', 'Data Architect', 'Data quality', 'Informatica', 'SQL', 'Python', 'Data architecture']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeRecruitment / Staffing,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
Eli Lilly and Company strives to create informative and engaging online communities that share information in meaningful ways. We welcome and encourage your participation and engagement in thoughtful and respectful discourse.,"RoleTechnical Architect,",Not Disclosed,5 - 7 years,Bangalore/Bengaluru,"Job description       Deep technical understanding of various data architectures and solution options along with an understanding of business requirements.    Deep understanding of cloud technologies and strategies including knowledge on cloud infrastructure (Azure/ AWS)    Ability to create roadmaps through working with multiple stakeholders Global Technology Teams and Business    Translating requirements into technical design and architecture, aligned with enterprise and industry standards and best practices, along with the corresponding required documentation.    Well-versed in both the evolving technology landscape as well as the needs of the business areas they support.    Has a deep understanding of data sources, flows, integration, acquisition, structures, quality, harmonization, and governance.    Translate business requirements into consumable data models and source to target data mapping.    Consult with internal customers who own the data to develop information relationships that lead to actionable insights.    Work with data from multiple data sources to build integrated views that will drive decisions.    Work in Agile Sprints with business facing project teams.      Additional Responsibilities        Collaborates with architects on technical design issues, particularly for solutions that impact local and global business areas    Work with Global Engineering Business Partners and Sites to understand business problems and set IT direction roadmap for solutions to meet business needs    Work with central and site engineering business partners and define processes for capture and maintaining engineering data, such as equipment metadata, supporting to the goal of creating an equipment digital twin for key process equipment sets and integration of this metadata with various sources of data.    Perform data issue analysis and work with various MQ teams to improve data quality confidence.    Serve as the technical liaison between the Bigdata Engineering admins, Data Scientists, Data Engineers and Product Owners.    Validate data quality coverage and accuracy by developing reports and tools to monitor and visualize data quality    Support the effort in finding data quality gaps by working with business and across IT domains to identify process or data management changes.    Work with Data Integration Developers to build solutions.    Work closely with the Data Integration and Analytics team to ensure we are in sync with the NextGen data lake    Develop deep understanding of technologies that enable business processes within key areas.    Develop solid understanding of business processes and needs to support recommended technical direction.    Responsible for ensuring adherence to technology roadmaps driven by the Lilly Enterprise Architecture community.    Drives decisions with respect to technologies and use of those technologies.    Ensure interface and data needs are understood and that the necessary technology and architecture are in place to meet these needs.    Responsible for understanding, influencing, and evolving the supported application(s) technical design.    Understanding of current technology as well as future direction for the area and the enterprise.        Basic Requirements      BachelorDegree and 5 yearsexperience in the implementation of modern data ecosystems.    Expertise in Python, SQL, Hadoop, Hive, Spark, UNIX Shell scripting, and Informatica big data technologies.    Expertise with JSON, REST API, and other data integration technologies.    Experience in one or more cloud-based data solutions/ cloud infrastructure    Demonstrated understanding of data privacy and CCI requirements and experience delivering within those requirements.    Experience in applying quality and compliance requirements.    Excellent oral and written communication skills.    Fluency in English.    A high level of intellectual curiosity, external perspective, and innovation interest    Strong analytical, problem solving and investigative skills    Experience with security models and development on large data sets    Excellent self-management skills.    RoleTechnical Architect,Industry TypePharmaceutical & Life Sciences,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsComputer scienceData managementAgileHealthcareJSONInformaticaUnix shell scriptingAnalyticsSQLPython","['Computer science', 'Data management', 'Agile', 'Healthcare', 'JSON', 'Informatica', 'Unix shell scripting', 'Analytics', 'SQL', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypePharmaceutical & Life Sciences,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
Eli Lilly and Company strives to create informative and engaging online communities that share information in meaningful ways. We welcome and encourage your participation and engagement in thoughtful and respectful discourse.,"RoleDatabase Architect / Designer,",Not Disclosed,5 - 10 years,Bangalore/Bengaluru,"Job description       Minimum 5 years Pharmaceutical Manufacturing experience.Knowledge of GxP, Supply Chain, Pharmaceutical manufacturing processes and automations systems    Minimum 5 years of relevant experience with data architecture design    Experience in Computer System Validation processes and Data Integrity concepts    Excellent communication, interpersonal, and influencing skills.    Ability to carry on conversations with business customers, upper management, and technical personnel.    Experience in working in an international and multicultural environment where team members are spread into different countries    Ability to thrive in a complex, changing, virtual environment with multiple competing priorities    Strong problem solving and organizational skills    A high level of intellectual curiosity, external perspective, and innovation interest    Strong analytical, problem solving and investigative skills    Experience with security models and development on large data sets    Demonstrated understanding of data privacy and CCI requirements and experience delivering within those requirements.    Excellent self-management skills.          Technology Background:      Experience with Agile Methodology    ITIL certification    Knowledge of best practices for code review and management in GitHub    Experience in design and development of data lakes, data warehouses, data marts and schema design    Building and maintaining complex data pipelines    Expertise in performing data extraction, profiling, cleansing, conversion, transformation and loading of data    Knowledge of CI/CD, Infrastructure as Code and more generally Everything as Code    Experience with DBMS software and tools (PostgreSQL, Oracle, Snowflake, Teradata, MS SQL Server, MongoDB, Toad, Hadoop, CouchDB, etc.)    Expertise in data management (structured/unstructured), data mining and reporting technologies    Extensive experience with data modeling using Erwin, PowerDesigner, Toad or similar software    Experience working with Amazon AWS, Microsoft Azure, Spark framework    Experience with a multitude of AWS services; especially Glue, DMS, CloudFormation, IAM, Route53, ALB/ELB, VPC, EC2, Lambda, S3, KMS, CloudTrail, Config, CloudWatch    Experience with Azure services; especially Azure Data Factory, Azure Resource Manager, Azure Synapse, Azure Functions, Azure Data Lake Analytics, Azure Data Lake Storage, Azure Monitor    Experience with SQL, PL/SQL, Python, Spark Framework, YAML, JSON, Chef    Experience with Docker, NodeJS, Ansible, Docker, Jenkins, Unix, Linux    Strong understanding of cybersecurity operation principles    Knowledge of industry standard NIST framework        Additional Preferences:      Knowledge of data science technologies like R, Keras or TensorFlow    Knowledge of ML/AI and natural language processing    Experience implementing and leading data governance    Experience working in a regulated environment    Manufacturing Operations experience preferred    Pharma Manufacturing experience strongly desired.    Multi-Site, Global IT Project Experiences strongly desired    RoleDatabase Architect / Designer,Industry TypePharmaceutical & Life Sciences,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsUnixMS SQLLinuxData modelingData ArchitectPLSQLJSONOracleTeradataPython","['Unix', 'MS SQL', 'Linux', 'Data modeling', 'Data Architect', 'PLSQL', 'JSON', 'Oracle', 'Teradata', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypePharmaceutical & Life Sciences,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Triangle ( A Unit of Ratein Infotech India Private Ltd) is a Recruitment Specialist Organisation with focus on Information Technology Industry. Incorporated in August 2000 with 4 offices in India at Mumbai, Pune, New Delhi & Bangalore, Triangle caters to more than 25 active clients who are Fortune 500 organizations and world¢??s largest IT organizations.  Our Core expertise is in End to End Permanent and Contract Staffing and Extended Services.  We have been Internationally recognized as WeConnect Certified woman owned and managed organization.  Triangle has featured in CIO Review Magazine as ¢??Company of the Year in Staffing and Recruitment¢? Category for year 2014.","RoleTechnical Architect,",Not Disclosed,10 - 15 years,Bangalore/Bengaluru,"Job description    Azure Data Architect with streaming experience Total experience in data management area for 10 + years with Azure cloud data platform experience        Architect with Azure stack (ADLS, AALS, Azure Data Bricks, Azure Streaming        Analytics Azure Data Factory, cosmos DB Azure synapse) mandatory expertise on Azure streaming Analytics ,Data Bricks, Azure synapse, Azure cosmos DB        Must have worked experience in large Azure Data platform and dealt with high volume Azure streaming Analytics        Experience in designing cloud data platform architecture, designing large scale environments        5 plus Years of experience architecting and building Cloud Data Lake, specifically Azure Data Analytics technologies and architecture is desired,      Enterprise Analytics Solutions. ‚Leading development of Data Lake Architectures from scratch for streaming Analytics Platform ‚5+ years of Programming experience in Python, SQL, Spark ‚Experience on Azure data explorer (ADX) is good to have it       RoleTechnical Architect,Industry TypeRecruitment / Staffing,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData managementArchitectural designData ArchitectCloudProgrammingData analyticsArchitectingCosmosSQLPython","['Data management', 'Architectural design', 'Data Architect', 'Cloud', 'Programming', 'Data analytics', 'Architecting', 'Cosmos', 'SQL', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeRecruitment / Staffing,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
" Thanks & Best Regards,Hemalatha| Lead Talent Acquisition  www.cygnuspro.comCygnusPro Software Solutions Pvt. Ltd.Tel:     04068196805Mob:  9989759380email:  hemalatha@cygnuspro.com","RoleData warehouse Architect / Consultant,",Not Disclosed,15 - 20 years,Bangalore/Bengaluru,"Job description  Exp  15 + Yrs ,  Expertise in IICS Data Integration & App Integration                              Good Data Solutioning  Experience                              Exposure to Snowflake / Data Bricks                              Exposure to Java / Python will be added advantage                                Strong stakeholder management & Communication skills                              Exposure to Informatica EDC / Axon & MDMRoles and Responsibilities Desired Candidate Profile   Exp  15 + Yrs ,  Expertise in IICS Data Integration & App Integration                              Good Data Solutioning  Experience                              Exposure to Snowflake / Data Bricks                              Exposure to Java / Python will be added advantage                                Strong stakeholder management & Communication skills                              Exposure to Informatica EDC / Axon & MDMPerks and Benefits RoleData warehouse Architect / Consultant,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, Temporary/ContractualRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData SolutioningIICS Data Integration and App IntegrationInformatica EDC / Axon & MDMJava / PythonSnowflake / Data BricksSkills highlighted with ‘‘ are preferred keyskills","['Data Solutioning', 'IICS Data Integration and App Integration', 'Informatica EDC / Axon & MDM', 'Java / Python', 'Snowflake / Data Bricks']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Temporary/Contractual",Role CategoryDBA / Data warehousing
"Our Company is a guaranteed for its exceptional ELDF ( Enterprise Level Solution Development Firm ) for giving the particular services to different businesses with numerous physio-graphic puts over the world. We make the association for the intellectual business by working with up and coming latest advancements to serve the best client experience through customized benefits and upgraded collaboration.We are having a range of products like Customized ERP, Smart Dashboard, Audit, CRM and IOT.","RoleTechnical Architect,",Not Disclosed,8 - 15 years,Kolkata,"Job description     Good Understanding of Distributed Data Platforms.    Should have worked as data architect in Implementing a medium/large scale Data Warehouse solution.    Experience in Migrating Legacy Data Warehousing Solution to GCP Cloud.    Deep exposure hands-on GCP Cloud Native ETL / ELT services with deep understanding of BigQuery and Looker or any other reporting platform.    Possess in depth knowledge and hands on development experience operationalizing large scale ingestion, processing, consumption using either DataProc or Dataflow or cloud fusion.    Strong understanding and experience with Storage infrastructure, event-based architecture using Cloud Functions, Monitoring, Logging, Auditing services of GCP.    Strong experience on either one or more MPP Data Warehouse Platforms prefer BigQuery, CloudSQL, Cloud Spanner, Fire store or similar.    Strong Development Experience on at least one or more event-driven streaming platforms prefer PUB/SUB, Kafka   Exposure to Networking on GCP and Gateway connectivity.    Strong Data Orchestration experience using tools such has Cloud Functions, Dataflow, Cloud Composer, Apache Airflow or related.   RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsSUBorchestrationNetworkingGCPCloudData Architectcloud storageApacheData warehousingMonitoring","['SUB', 'orchestration', 'Networking', 'GCP', 'Cloud', 'Data Architect', 'cloud storage', 'Apache', 'Data warehousing', 'Monitoring']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"Triangle ( A Unit of Ratein Infotech India Private Ltd) is a Recruitment Specialist Organisation with focus on Information Technology Industry. Incorporated in August 2000 with 4 offices in India at Mumbai, Pune, New Delhi & Bangalore, Triangle caters to more than 25 active clients who are Fortune 500 organizations and world¢??s largest IT organizations.  Our Core expertise is in End to End Permanent and Contract Staffing and Extended Services.  We have been Internationally recognized as WeConnect Certified woman owned and managed organization.  Triangle has featured in CIO Review Magazine as ¢??Company of the Year in Staffing and Recruitment¢? Category for year 2014.","RoleTechnical Architect,",Not Disclosed,10 - 15 years,Bangalore/Bengaluru,"Job description    Azure Data Architect with streaming experience Job description Total experience in data management area for 10 + years with Azure cloud data platform experience Architect with Azure stack (ADLS, AALS, Azure Data Bricks, Azure Streaming Analytics Azure Data Factory, cosmos DB Azure synapse) mandatory expertise on Azure streaming Analytics ,Data Bricks, Azure synapse, Azure cosmos DB Must have worked experience in large Azure Data platform and dealt with high volume Azure streaming Analytics Experience in designing cloud data platform architecture, designing large scale environments 5 plus Years of experience architecting and building Cloud Data Lake, specifically Azure Data Analytics technologies and architecture is desired, Enterprise Analytics Solutions, and optimizing real time big data data pipelines, architectures and data sets     Job Description Architecting Microsoft Azure Solutions across multiple platforms    Implementation and Delivery of Microsoft Azure projects    Documentation of solutions (eg architecture, configuration and setup)    Working within a project management/agile delivery methodology in a leading role as part of a wider team    Experience of setting up, deploying and managing multiple environments to support agile development approaches hands-on experience with DevOps toolset    Knowledge of PowerShell, Git, ARM templates and deployment automation 10+ years of industry experience   Designing / Developing / Envisioning Enterprise apps using Azure IaaS and Analytics services with a focus on Azure RBAC, Azure AD, Azure Data Factory, Azure Data Lake Storage, Azure Function App, Azure Data Warehouse, Azure SQL DB, Azure Databricks      RoleTechnical Architect,Industry TypeRecruitment / Staffing,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsAutomationGITData managementPowershellProject managementAgile developmentData ArchitectArchitectural designCosmosSQL","['Automation', 'GIT', 'Data management', 'Powershell', 'Project management', 'Agile development', 'Data Architect', 'Architectural design', 'Cosmos', 'SQL']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeRecruitment / Staffing,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services — all powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. Our 674,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at accenture.com","RoleTechnical Architect,",Not Disclosed,12 - 15 years,Bangalore/Bengaluru,"Job description  Project Role :  Data Architect    Project Role Description :  Define the data requirements and structure for the application. Model and design the application data structure, storage and integration.    Management Level :  7    Work Experience :  12-15 years    Work location :  Bengaluru    Job Requirements :        Key Responsibilities :   1Function as the Lead Data Architect for a small, simple project/proposal or as a team lead for medium/large sized project or proposal2Discuss specific data architecture and data related issues with client architect/team in area of expertise3Analyze and assess the impact of the requirements on the data and its lifecycle4Lead the data architecture and design of complex, enterprise-level applications and systems5Breadth of experience in various client scenarios and situations     Technical Experience :   1Strong experience in Azure is preferred with hands-on experience in 2 or more of these skills : Azure SQL DB ,Azure SQL Managed Instance ,Azure Data Lake Store, Azure Cosmos DB, Azure Database for PostgreSQL, Azure Database for MySQL2Experience in handling medium to large data migration projects3 5 years of extensive database experience design build     Professional Attributes :   1Should be able to drive the technology design meetings, propose technology design and architecture 2Should have excellent client communication skills3Should have good analytical and problem-solving skills     Educational Qualification :   1Must have: BE/BTech/MCA 2Good to have: ME/MTech  RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :B.Tech/B.E.PG :MCA in Computers, M.TechKey SkillsData migrationPostgresqlMySQLConsultingSQLArchitectureAnalyticalCosmosData architectureSkills highlighted with ‘‘ are preferred keyskills","['Data migration', 'Postgresql', 'MySQL', 'Consulting', 'SQL', 'Architecture', 'Analytical', 'Cosmos', 'Data architecture']","['UG :B.Tech/B.E.', 'PG :MCA in Computers, M.Tech']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
Leading Client,"RoleTechnical Architect,",Not Disclosed,11 - 14 years,Bangalore/Bengaluru,"Job descriptionJob Description : Big Data Architect Function : Data Integration Location : Off Shore / India Basic Function : - The Big Data Architect works closely with the customer and the solutions architect to translate the customer's business requirements into a Big Data solution. - This includes understanding the customer data requirements, platform selection, design of the technical architecture, design of the application and interfaces, and development, testing, and deployment of the proposed solution. - Has the ability to design enterprise grade large-scale data processing systems and help identify the best options for architecture. - The Big Data Architect also understands the complexity of data and can design systems and models to handle different variety of data with varying levels of volume, velocity and veracity. - Should have independently worked on proposing architecture, design and data ingestion concepts in a consultative mode. - Leads client assessments, preparing current state and future state architectures along with go forward recommendations. - Will work with the practice leads and account management team to develop statements of work, implementation plans, resource plans and project estimates Essential Functions : - Has a deep understanding and experience with several of the following: Business Analysis, Requirements Gathering, Data Analysis, Data Modeling, Project Management, Project Estimation - Advanced knowledge of design and architecture patterns and methodologies. - Demonstrated work ethic, focus and self-discipline - Has and maintains a deep understanding of the role of big data in business and the enterprise. - Propose recommended and/or best practices regarding the movement, manipulation, and storage of data in a big data solution including data ingestion, data storage options, query techniques, data variety, volume & velocity, - Collaborate with project teams on platform development process from inception to production deployment, including project scheduling, design, implementation and coordination with other team members. - Collaborate with other technology teams and architects to define and develop cross- function technology stack interactions. - Research and experiment with emerging technologies and tools related to big data. - Experience in scaling applications on big data platforms to massive size. - Performing solution architecture in adherence to enterprise architecture governance. - Bridging business and development team. - Long term development and Technical expertise in DW/BI Practice, communicate well with all stakeholders, optimize objectives, leverage state of the art tools and best practices, integrate into corporate systems and deliver on time. - Deep understanding in Data Warehousing, Enterprise Architectures, Dimensional Modelling, Star & Snow-flake schema design, Reference DW Architectures, ETL Architect, ETL (Extract/Transform/Load), Data Analysis, Data Conversion/Transformation, Database Design, Data Warehouse Optimization, Data Mart Development, and Enterprise Data Warehouse Maintenance and Support etc. - Should have independently worked on proposing architecture, design and data ingestion concepts. Primary Internal Interactions : Project Delivery : - Formulates workable solutions that integrate people, process and technology. Integrates competency leads and other subject matter experts to define the details of vision and solution - Identifies, creates and communicates the vision of the end-to-end solution for the client and implementation teams after completing thorough evaluations of the present state needs - Leads technical teams in documenting and implementing technical solutions for business problems - Supports Delivery Enablement and Practice Leads by ensuring appropriate linkage between practices is clear and well understood - Works with practice leads to develop project estimating methodologies for new areas of focus Account & Resource Management : - Partners with the account teams to identify and sell solutions and create high level of client interest in proposed comprehensive solutions - Works closely with Engagement Managers, Account Managers and Account Leads in strategies to grow existing accounts - Partners with account team and client to develop the ROI, Business Case, and Statement of Work for an engagement - Develops comprehensive project, implementation, and resource plans working closely with Engagement and Project Managers Primary External Interactions : Assessment Participation & Leadership : - Identifies, creates and communicates the vision of the end-to-end solution for the client and implementation teams after completing thorough evaluations of the present state needs - Participates in strategy development and current state assessments for clients to identify opportunities. Acts as proxy for practice leads when necessary - Works with client to sell the proposed solution and develop internal marketing programs - Supports work that may not fall into an existing competency and helps to identify possible needs for new competencies. - Partners with account team and client to develop the ROI, Business Case, and Statement of Work for an engagement Organizational Relationships : Reports To : EDM India Practice Lead - over time, this will evolve Supervises : NA Skills : Technical Skills (Knowledge, Skills & Abilities) : - Experience with enterprise data management, Business Intelligence, data integration, and SQL database implementations - Experience with the major big data solutions like Hadoop, MapReduce, Hive, Spark, Scala, HBase, MongoDB, Cassandra. - Programming/scripting languages like Java, Linux, PHP, Ruby, Python and/or R. As well as have experience in working with ETL tools such as Informatica, Talend, Pentaho etc. - He or she should have experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms. - Experience in data migration from relational databases to Hadoop HDFS - Propose best practices/standards - Translate, load and present disparate datasets in multiple formats/sources including JSON, XML etc. Must Have Skills : - Hadoop stack including HDFS cluster, MapReduce, Hive, Spark and Impala - Web Technologies CSS, DHTML, XML, Hight Charts, Linux - ETL tools such as Informatica, Talend and/or Pentaho. Query : SQL, No SQL Concepts Ingest : Kafka, Sqoop, Flume Orchestration : Zookeeper Databases : Postgres, Mongo DB, Cassandra, HBase Languages : Java, Scala Scripting : JavaScript, DHTML, XML, Shell Good to have Skills : Core : AWS, Hadoop, Yarn Process : Agile-Scrum, Iterative Development, DevOps, CI Analytics : Descriptive, Predictive (Added advantage) Tools : Jenkins and TFS Languages : Python, Java Enterprise Process Specific Skills : (Supervisory Responsibilities) : - When the Bigdata Architect is acting as an engagement or project manager, they will be responsible for the overall supervision of the staff on the engagement.- They will be responsible for coaching and advising the team on the engagement. They will likely need to provide feedback to the people managers and practice leads of the resources on their engagement team. Soft skills (Desired) :- Experience working with multi-divisional business communities to leverage information across the enterprise to improve business effectiveness - Strong team building, interpersonal, analytical, problem identification and resolution skills Soft Skills (Minimum) : - Exceptional analytical, conceptual, and problem-solving abilities - Strong written/oral communication and presentation/interpersonal skills - Highly self-motivated and able to work independently as well as in a team environment Education Requirements : Bachelor's degree or Master's degree Work Experience Requirements : - Minimum 10 years of professional experience with BI/DW implementations and with at least 2-3 years of Big Data Architecture. - 3+ years of experience in technical or solution architecture providing large scale enterprise data solutions. RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateDoctorate :Doctorate Not RequiredKey SkillsDatabase MaintenanceTechnical ArchitectBig Data ArchitectBusiness IntelligenceHadoopBig DataDatabase DesignData AnalystData WarehousingData ModelingMapReduceSkills highlighted with ‘‘ are preferred keyskills","['Database Maintenance', 'Technical Architect', 'Big Data Architect', 'Business Intelligence', 'Hadoop', 'Big Data', 'Database Design', 'Data Analyst', 'Data Warehousing', 'Data Modeling', 'MapReduce']","['UG :Any Graduate', 'PG :Any Postgraduate', 'Doctorate :Doctorate Not Required']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"We Are Brillio. Born of the digital age in 2014. We are laser-focused on turning technological disruptions into the advantages that our customers need to thrive in todays digital economy.Brilliois a company focused on digital technologies andbig dataanalytics headquartered inSanta Clara, California, United States","RoleDatabase Architect / Designer,",Not Disclosed,6 - 10 years,Bangalore/Bengaluru,"Job description  BSc or MSc (preferred) in a STEM field Relevant work experience of 5 years Fluency in Python (especially Numpy and Pandas) and familiarity in PySpark Extensive hands-on experience with AWS Analytical Components like S3, EC2, Lambdas, Glue, SQS, SNS, DynamoDB, Redshift, RDS etc.    Experience with Data Lake Formation and Athena    Work Experience with industry standard distributed systems (ie    Spark, hive), data pipeline tools (ie    Airflow), NoSQL Databases (DynamoDB) and databases (PostgreSQL) Experience with Data Analysis, Significant experience optimizing data retrieval processes supporting API output, ideally within a low query volume / high data volume environment    Demonstrably deep experience with relevant big data processing either via Spark or through a modern MPP database like Redshift, ideally with experience in both Demonstrably deep experience with CI/CD tools and practices in a containerized AWS environment, from deployment pipelines (Jenkins, etc), infrastructure definition (Terraform, CloudFormation, etc    Understand and design for non-functional concerns such as performance, cost optimization, maintainability, and developer experience.             RoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData analysisNoSQLAnalyticalPostgresqlData ArchitectData processingbig dataDistribution systemCost optimizationPython","['Data analysis', 'NoSQL', 'Analytical', 'Postgresql', 'Data Architect', 'Data processing', 'big data', 'Distribution system', 'Cost optimization', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Coforge is a leading global IT solutions organization, enabling its clients to transform at the intersect of unparalleled domain expertise and emerging technologies to achieve real-world business impact. A focus on very select industries, a detailed understanding of the underlying processes of those industries, and partnerships with leading platforms provide us a distinct vantage. We leverage AI, Cloud, and Insight-driven technologies, allied with our industry expertise, to transform client businesses into intelligent, high growth enterprises. Today our proprietary platforms power critical business processes across the Financial Services and Travel industries. Our 23,500 technology and process consultants engineer, design, consult, operate, and modernize systems across the world. Coforge is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity, or any other basis as protected by applicable law.","RoleData warehouse Architect / Consultant,",Not Disclosed,10 - 15 years,Noida,"Job descriptionData Architect:  At least 10 years of professional data modeling experience.  Expert in Data modeling:  •	Data Vault 2.0 •	Dimensional modelling •	3NF modelling Business requirement:  •	Ability to engage with business stakeholders •	Structure approach to Business requirement gathering •	Ability to break down business requirement into KPI’s, Dimensions and Facts ETL architecture Data warehousing patterns (Kimball/Inmon) Knowledge of data modelling tools i.e. SAP Powerdesigner, Wherescape 3D, Erwin Knowledge of SQL Power BI knowledge (nice to have) Snowflake/ AWS knowledge (nice to have) Please share resumes on priyata.singh@coforge.comRoleData warehouse Architect / Consultant,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateDoctorate :Any DoctorateKey SkillsData ModelingData VaultData ArchitectureSkills highlighted with ‘‘ are preferred keyskills","['Data Modeling', 'Data Vault', 'Data Architecture']","['UG :Any Graduate', 'PG :Any Postgraduate', 'Doctorate :Any Doctorate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
Leading Client,"RoleDatabase Architect / Designer,",Not Disclosed,3 - 8 years,Bangalore/Bengaluru,"Job description- Create and maintain optimal data pipeline architecture- Assemble large complex data sets that meet functional business requirements- Identify, design, and implement internal process improvements- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other data technologies- Build analytical tools that utilize the data pipeline to provide actionable insight into customer acquisition, operational efficiency, and other key business performance metricsPeople should have :- Master's or Bachelor's degree in computer science or information technology- Extensive knowledge about various programming languages- Technical expertise with data models, data mining, and segmentation techniques- Experience with SQL database design- Creative problem solving and strong communication skills- Strong numerical and analytical skills with the demonstrated ability to research and make decisions based on the day-to-day and complex customer problems requiredRoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :BCA in ComputersPG :MCA in ComputersDoctorate :Doctorate Not RequiredKey SkillsData PipelineData MiningPythonJavaData ModelingSQLSkills highlighted with ‘‘ are preferred keyskills","['Data Pipeline', 'Data Mining', 'Python', 'Java', 'Data Modeling', 'SQL']","['UG :BCA in Computers', 'PG :MCA in Computers', 'Doctorate :Doctorate Not Required']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
ASPIRE SYSTEMS,"RoleDatabase Architect / Designer,","₹ 17,00,000 - 30,00,000 P.A. ",12 - 15 years,Chennai,"Job descriptionRoles and Responsibilities  Expertise in understanding the Functional Requirements and do the modelling of DWH Expertise in understanding the Data integration across the landscape Expertise in designing ETL packages. Expertise in job scheduling, debugging, enhancement of ETL jobs Expertise in Designing DWH, STAR schema, SNOWFLAKE schema Good knowledge in creating stored procedures and functions Good Knowledge in Performance tuning of SSIS, Tsql queries Should handle large volume of data sync using any ETL tool Understanding of non-functional requirements Should be proficient in understanding DWH, mpp systems, OLTP, and OLAP systems. Should document the code and functional changes A good team player and excellent communicator   AWS Architect (ETL and Data Architect) Years of Experience : 12 years and above Location : Chennai/Bangalore Onsite option available - Dubai Interview : Two technical rounds of interview Tools and Skills : Apache airflow, MySQL,AWS GLUE, POSTGRES , TALEND AND ANY DATA MODELLING TOOLS , REDSHIFTS, POSTGRES.RoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduateKey SkillsApache AirflowArchitectureAWS gluePostgresAWSsql server any of these DatabasesMysqlTalend and any data modelling tools.  RedshiftSkills highlighted with ‘‘ are preferred keyskills","['Apache Airflow', 'Architecture', 'AWS glue', 'Postgres', 'AWS', 'sql server any of these Databases', 'Mysql', 'Talend and any data modelling tools.  Redshift']",['UG :Any Graduate'],"Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Founded in 1976, CGI is among the largest IT and business consulting services firms in the world. Operating in hundreds of locations across the globe, CGI delivers end-to-end services and solutions, including strategic IT and business consulting, systems integration, intellectual property, and managed IT and business process services","RoleDatabase Architect / Designer,",Not Disclosed,3 - 8 years,Bangalore/Bengaluru,"Job descriptionPosition Description:Act as the primary point of contact within the organization for members of staff, regulators, and any relevant public bodies on issues related to data protectionEnsure the company’s policy is in accordance with General Data Protection Regulation (GDPR) and codes of practiceEvaluate the existing data protection framework and identify areas of non or partial compliance and rectify any issuesDevise training plans and provide data protection advice and support for members of staffInform and advise the Data Controller or Data Processor on all matters related to data protectionPromote a culture of data protection compliance across all units of the organizationDaily and Monthly ResponsibilitiesProvide expert advice and educate employees on important data compliance requirementsDraft new and amend existing internal data protection policies, guidelines, and procedures, in consultation with key stakeholdersHold training with staff members across different business units who are involved in data handling or processingProactively conduct audits to ensure compliance and address potential issuesMaintain records of all data processing activities carried out by the companyServe as the point of contact between the company and the data protection authoritiesMinimum of three years experience working in data protection compliance or a related fieldExpertise in European data protection laws and practices including an in-depth understanding of the GDPRExperience within a legal, audit and/or risk function departmentAbility to manage sensitive and confidential informationOwn and keep under constant review all the organization’s global data protection compliance arrangements to include updating policies and guidance, centralising processes and putting in place robust, time-bound remedial plans where necessary.Develop and maintain relevant global internal data privacy policies and training.Inform and advise the global organization on the Global Data Protection Regulation (GDPR) and its requirements, liaising with local support as required. Serving as a subject matter expert and developing and implementing a robust compliance plan.Partner with all key business areas, in particular the IT Security team, to ensure data privacy issues are considered at the outset of new projects, products and initiatives Act as a liaison between onshore and offshore teams in relation to global data privacy issues.Help manage the data privacy network across all global offices.Handle enquiries and issues relating to data privacy practices, withdrawal of consent, the right to be forgotten, and related rights.Monitor the industry landscape to keep visibility on evolutions, trends, and best practices related to Data PrivacyEnsure that systematic compliance audits are undertaken and that their findings are reported and acted upon.Demonstrate deep knowledge of data privacy, data handling and data classification.Demonstrate experience of managing data privacy issues in a global organisation.Expertise in global and European data protection laws and practices and an in-depth understanding of the GDPR.Capable of conducting data privacy compliance reviews and audits.Have the ability to develop awareness and communications at all levels within the organizationAbility to review, analyse and organise documentary and factual evidence. Skills:Data ArchitectureRoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData Privacyaudit complianceit securitydata managementhp data protectordata classificationdata processingSkills highlighted with ‘‘ are preferred keyskills","['Data Privacy', 'audit compliance', 'it security', 'data management', 'hp data protector', 'data classification', 'data processing']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services — all powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. Our 674,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at accenture.com","RoleTechnical Architect,",Not Disclosed,6 - 8 years,Bangalore/Bengaluru,"Job description  Project Role :  Data Architect    Project Role Description :  Define the data requirements and structure for the application. Model and design the application data structure, storage and integration.    Management Level :  9    Work Experience :  6-8 years    Work location :  Bengaluru    Job Requirements :        Key Responsibilities :   aFunction as the Lead Data Architect for a small, simple project/proposal or as a team lead for medium/large sized project or proposalbDiscuss specific Big data architecture and related issues with client architect/team in area of expertisecAnalyze and assess the impact of the requirements on the data and its lifecycledLead Big data architecture and design medium-big Cloud based, Big Data and Analytical Solutions using Lambda architectureeBreadth of experience in various client scenario     Technical Experience :   aStrong experience in Azure is preferred with hands-on experience in two or more of these skills : Azure Synapse Analytics, Azure HDInsight, Azure Databricks with PySpark / Scala / SparkSQL, Azure Analysis ServicesbExperience in one or more Real-time/Streaming technologies including: Azure Stream Analytics, Azure Data Explorer, Azure Time Series Insights, etccExperience in handling medium to large Big Data implementationsdFor Level 8 - Candidate must have 10-12 years of IT experience     Professional Attributes :   aShould be able to drive the technology design meetings, propose technology design and architecture bShould have excellent client communication skillscShould have good analytical and problem-solving skills     Educational Qualification :   aMust have: BE/Btech/MCA bGood to have: ME/Mtech  RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :B.Tech/B.E.PG :MCA in Computers, M.TechKey SkillsAnalyticalConsultingSCALAAnalyticsData architectureArchitecturebig dataSkills highlighted with ‘‘ are preferred keyskills","['Analytical', 'Consulting', 'SCALA', 'Analytics', 'Data architecture', 'Architecture', 'big data']","['UG :B.Tech/B.E.', 'PG :MCA in Computers, M.Tech']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"A Silicon-Valley headquartered company, Infogain is a global business oriented IT consulting provider of front-end, customer-facing technologies, processes and applications, leading to a more efficient and streamlined customer experience. We want our clients€™ interactions with their customers to be fast, efficient, and cost effective.With close to 4,000 employees in the United States, India, the Middle East, U.K., Singapore and Malaysia, we service 5 of the world€™s largest 50 companies, and 24 of the Fortune 500. we have million-dollar engagements with over 25 customers, many of which have been with us for 5 years or more.At Infogain, we place a high value on establishing long-term relationships with our clients, ultimately becoming virtual extensions of their organizations. In fact, more than 90% of our medium and large deal size clients from five years ago remain clients today. Why? Our consultants, project managers and engineering teams listen and address our clients€™ specific requirements with best-in-class solutions across a broad spectrum of service areas.Infogain is an Oracle Knowledge Management Expert, having the world€™s largest practice to improve customer support operations and boost satisfaction in High Tech, Insurance, Travel & Hospitality and Retail.We are also a global leader in Oracle Retail€™s customer facing products.For insurance companies, Infogain helps make the claims process more efficient, effective and customer friendly.","RoleData Engineer,",Not Disclosed,8 - 11 years,Noida,"Job descriptionGreeting form Infogain! We are having Immediate requirement for Azure Data Architect in Infogain India Pvt Ltd. Please Find the Job Description below & If you are interested please share your updated Resume with details:-Mode of Hiring-PermanentExperince-8-12 YrsSkills Required- ADF, SQL, MS SQL Server, SynapseNotice Period- Immediate to 30 Days MaxLocation- Noida/Bangalore/Pune/Mumbai (Currently work from home)Job Description 6+ Years experience in Azure Stack(ADF, ADLS, Synapse, Databricks, PowerBI) and strong Data Warehouse, SQL DB, Data Modelling Skills. Hands-on exposure to coding and mentor team on technical abilities Kindly share your update word formatted /pdf profile with the details below on arti.sharma@infogain.com Total exp-Exp in ADFExp in SynapseExp in DatabricksCurrent CTC:Exp CTC:NP -Current Location-Preferred Location- About Infogain:Infogain is a Silicon Valley headquartered company with expertise in software platform engineering and deep domain skills in travel, retail, insurance, automotive, and high technology. We accelerate the delivery of digital customer engagement systems using digital technologies such as cloud, microservices, robotic process automation, and artificial intelligence for our clients. Our unique engagement approach of Listen-Curate-Deliver helps to accelerate the innovation journey of 5 of the worlds largest 50 companies and 24 of the Fortune 500, with several relationships of over 10 years. We deliver positive business outcomes using rapid prototyping and a solid foundation of DevOps-based software platform engineering that ensure high-quality and on-time delivery. Our 3,500 global employees across the US, UK, Singapore, Middle East and India focus on client value creation, delivery excellence and innovation. Our locations in India have 2700 employees spanning Noida, Pune, Mumbai and Bangalore.Infogain maintains both strategic and technology partnerships with leading enterprise software providers to deliver value-added solutions. We engage with the world's largest, as well as mid-size, and startup, software providers for building product capability, product marketing, customization, professional services and post-implementation supportRoleData Engineer,Industry TypeIT Services & Consulting,Functional AreaData Science & Analytics,Employment TypeFull Time, PermanentRole CategoryData Science & Machine LearningEducationUG :Any GraduatePG :Any PostgraduateDoctorate :Any DoctorateKey SkillsAzure Data FactoryADFSkills highlighted with ‘‘ are preferred keyskills","['Azure Data Factory', 'ADF']","['UG :Any Graduate', 'PG :Any Postgraduate', 'Doctorate :Any Doctorate']","Industry TypeIT Services & Consulting,","Functional AreaData Science & Analytics,","Employment TypeFull Time, Permanent",Role CategoryData Science & Machine Learning
"Triangle ( A Unit of Ratein Infotech India Private Ltd) is a Recruitment Specialist Organisation with focus on Information Technology Industry. Incorporated in August 2000 with 4 offices in India at Mumbai, Pune, New Delhi & Bangalore, Triangle caters to more than 25 active clients who are Fortune 500 organizations and world¢??s largest IT organizations.  Our Core expertise is in End to End Permanent and Contract Staffing and Extended Services.  We have been Internationally recognized as WeConnect Certified woman owned and managed organization.  Triangle has featured in CIO Review Magazine as ¢??Company of the Year in Staffing and Recruitment¢? Category for year 2014.","RoleSolution Architect,",Not Disclosed,10 - 15 years,Bangalore/Bengaluru,"Job description   Experience in architecting with AWS or Azure Cloud Data Platform Successfully implemented large-scale data warehouse / data lake solutions in snowflake or AWS Redshift Be proficient in Data modelling and data architecture design experienced in reviewing 3rd Normal Form and Dimensional models    Experience in implementing Master data management, process design and implementation    Experience in implementing Data quality solutions including processes    Experience in IOT Design using AWS or Azure Cloud platforms    Experience designing and implementing machine learning solutions as part of high-volume data ingestion and transformation    Experience working with structured and unstructured data including geo-spatial data    Experience in technologies like python, SQL, no SQL, KAFKA, Elastic Search Hands on experience using snowflake, informatica, azure logic apps, azure functions, azure storage, azure data lake and azure search    Behaviors Required: Driven by our values and purpose in everything we do Visible, active, hands on approach to help teams be successful Strong proactive planning ability    Optimistic, energetic, problem solver, ability to see long term business outcomes    Collaborative, ability to listen, compromise to make progress    Stronger together mindset, with a focus on innovation & creation of tangible / realized value      Education      Qualifications, Accreditation, Training: Required: Degree in Computer Science and/or related fields Azure or AWS Solution Architecture certifications    RoleSolution Architect,Industry TypeRecruitment / Staffing,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsComputer scienceSolution architectureProcess designMachine learningData ArchitectData qualityInformaticaSQLPythonData architecture","['Computer science', 'Solution architecture', 'Process design', 'Machine learning', 'Data Architect', 'Data quality', 'Informatica', 'SQL', 'Python', 'Data architecture']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeRecruitment / Staffing,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
Eli Lilly and Company strives to create informative and engaging online communities that share information in meaningful ways. We welcome and encourage your participation and engagement in thoughtful and respectful discourse.,"RoleTechnical Architect,",Not Disclosed,5 - 7 years,Bangalore/Bengaluru,"Job description       Deep technical understanding of various data architectures and solution options along with an understanding of business requirements.    Deep understanding of cloud technologies and strategies including knowledge on cloud infrastructure (Azure/ AWS)    Ability to create roadmaps through working with multiple stakeholders Global Technology Teams and Business    Translating requirements into technical design and architecture, aligned with enterprise and industry standards and best practices, along with the corresponding required documentation.    Well-versed in both the evolving technology landscape as well as the needs of the business areas they support.    Has a deep understanding of data sources, flows, integration, acquisition, structures, quality, harmonization, and governance.    Translate business requirements into consumable data models and source to target data mapping.    Consult with internal customers who own the data to develop information relationships that lead to actionable insights.    Work with data from multiple data sources to build integrated views that will drive decisions.    Work in Agile Sprints with business facing project teams.      Additional Responsibilities        Collaborates with architects on technical design issues, particularly for solutions that impact local and global business areas    Work with Global Engineering Business Partners and Sites to understand business problems and set IT direction roadmap for solutions to meet business needs    Work with central and site engineering business partners and define processes for capture and maintaining engineering data, such as equipment metadata, supporting to the goal of creating an equipment digital twin for key process equipment sets and integration of this metadata with various sources of data.    Perform data issue analysis and work with various MQ teams to improve data quality confidence.    Serve as the technical liaison between the Bigdata Engineering admins, Data Scientists, Data Engineers and Product Owners.    Validate data quality coverage and accuracy by developing reports and tools to monitor and visualize data quality    Support the effort in finding data quality gaps by working with business and across IT domains to identify process or data management changes.    Work with Data Integration Developers to build solutions.    Work closely with the Data Integration and Analytics team to ensure we are in sync with the NextGen data lake    Develop deep understanding of technologies that enable business processes within key areas.    Develop solid understanding of business processes and needs to support recommended technical direction.    Responsible for ensuring adherence to technology roadmaps driven by the Lilly Enterprise Architecture community.    Drives decisions with respect to technologies and use of those technologies.    Ensure interface and data needs are understood and that the necessary technology and architecture are in place to meet these needs.    Responsible for understanding, influencing, and evolving the supported application(s) technical design.    Understanding of current technology as well as future direction for the area and the enterprise.        Basic Requirements      BachelorDegree and 5 yearsexperience in the implementation of modern data ecosystems.    Expertise in Python, SQL, Hadoop, Hive, Spark, UNIX Shell scripting, and Informatica big data technologies.    Expertise with JSON, REST API, and other data integration technologies.    Experience in one or more cloud-based data solutions/ cloud infrastructure    Demonstrated understanding of data privacy and CCI requirements and experience delivering within those requirements.    Experience in applying quality and compliance requirements.    Excellent oral and written communication skills.    Fluency in English.    A high level of intellectual curiosity, external perspective, and innovation interest    Strong analytical, problem solving and investigative skills    Experience with security models and development on large data sets    Excellent self-management skills.    RoleTechnical Architect,Industry TypePharmaceutical & Life Sciences,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsComputer scienceData managementAgileHealthcareJSONInformaticaUnix shell scriptingAnalyticsSQLPython","['Computer science', 'Data management', 'Agile', 'Healthcare', 'JSON', 'Informatica', 'Unix shell scripting', 'Analytics', 'SQL', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypePharmaceutical & Life Sciences,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
Eli Lilly and Company strives to create informative and engaging online communities that share information in meaningful ways. We welcome and encourage your participation and engagement in thoughtful and respectful discourse.,"RoleDatabase Architect / Designer,",Not Disclosed,5 - 10 years,Bangalore/Bengaluru,"Job description       Minimum 5 years Pharmaceutical Manufacturing experience.Knowledge of GxP, Supply Chain, Pharmaceutical manufacturing processes and automations systems    Minimum 5 years of relevant experience with data architecture design    Experience in Computer System Validation processes and Data Integrity concepts    Excellent communication, interpersonal, and influencing skills.    Ability to carry on conversations with business customers, upper management, and technical personnel.    Experience in working in an international and multicultural environment where team members are spread into different countries    Ability to thrive in a complex, changing, virtual environment with multiple competing priorities    Strong problem solving and organizational skills    A high level of intellectual curiosity, external perspective, and innovation interest    Strong analytical, problem solving and investigative skills    Experience with security models and development on large data sets    Demonstrated understanding of data privacy and CCI requirements and experience delivering within those requirements.    Excellent self-management skills.          Technology Background:      Experience with Agile Methodology    ITIL certification    Knowledge of best practices for code review and management in GitHub    Experience in design and development of data lakes, data warehouses, data marts and schema design    Building and maintaining complex data pipelines    Expertise in performing data extraction, profiling, cleansing, conversion, transformation and loading of data    Knowledge of CI/CD, Infrastructure as Code and more generally Everything as Code    Experience with DBMS software and tools (PostgreSQL, Oracle, Snowflake, Teradata, MS SQL Server, MongoDB, Toad, Hadoop, CouchDB, etc.)    Expertise in data management (structured/unstructured), data mining and reporting technologies    Extensive experience with data modeling using Erwin, PowerDesigner, Toad or similar software    Experience working with Amazon AWS, Microsoft Azure, Spark framework    Experience with a multitude of AWS services; especially Glue, DMS, CloudFormation, IAM, Route53, ALB/ELB, VPC, EC2, Lambda, S3, KMS, CloudTrail, Config, CloudWatch    Experience with Azure services; especially Azure Data Factory, Azure Resource Manager, Azure Synapse, Azure Functions, Azure Data Lake Analytics, Azure Data Lake Storage, Azure Monitor    Experience with SQL, PL/SQL, Python, Spark Framework, YAML, JSON, Chef    Experience with Docker, NodeJS, Ansible, Docker, Jenkins, Unix, Linux    Strong understanding of cybersecurity operation principles    Knowledge of industry standard NIST framework        Additional Preferences:      Knowledge of data science technologies like R, Keras or TensorFlow    Knowledge of ML/AI and natural language processing    Experience implementing and leading data governance    Experience working in a regulated environment    Manufacturing Operations experience preferred    Pharma Manufacturing experience strongly desired.    Multi-Site, Global IT Project Experiences strongly desired    RoleDatabase Architect / Designer,Industry TypePharmaceutical & Life Sciences,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsUnixMS SQLLinuxData modelingData ArchitectPLSQLJSONOracleTeradataPython","['Unix', 'MS SQL', 'Linux', 'Data modeling', 'Data Architect', 'PLSQL', 'JSON', 'Oracle', 'Teradata', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypePharmaceutical & Life Sciences,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Triangle ( A Unit of Ratein Infotech India Private Ltd) is a Recruitment Specialist Organisation with focus on Information Technology Industry. Incorporated in August 2000 with 4 offices in India at Mumbai, Pune, New Delhi & Bangalore, Triangle caters to more than 25 active clients who are Fortune 500 organizations and world¢??s largest IT organizations.  Our Core expertise is in End to End Permanent and Contract Staffing and Extended Services.  We have been Internationally recognized as WeConnect Certified woman owned and managed organization.  Triangle has featured in CIO Review Magazine as ¢??Company of the Year in Staffing and Recruitment¢? Category for year 2014.","RoleTechnical Architect,",Not Disclosed,10 - 15 years,Bangalore/Bengaluru,"Job description    Azure Data Architect with streaming experience Total experience in data management area for 10 + years with Azure cloud data platform experience        Architect with Azure stack (ADLS, AALS, Azure Data Bricks, Azure Streaming        Analytics Azure Data Factory, cosmos DB Azure synapse) mandatory expertise on Azure streaming Analytics ,Data Bricks, Azure synapse, Azure cosmos DB        Must have worked experience in large Azure Data platform and dealt with high volume Azure streaming Analytics        Experience in designing cloud data platform architecture, designing large scale environments        5 plus Years of experience architecting and building Cloud Data Lake, specifically Azure Data Analytics technologies and architecture is desired,      Enterprise Analytics Solutions. ‚Leading development of Data Lake Architectures from scratch for streaming Analytics Platform ‚5+ years of Programming experience in Python, SQL, Spark ‚Experience on Azure data explorer (ADX) is good to have it       RoleTechnical Architect,Industry TypeRecruitment / Staffing,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData managementArchitectural designData ArchitectCloudProgrammingData analyticsArchitectingCosmosSQLPython","['Data management', 'Architectural design', 'Data Architect', 'Cloud', 'Programming', 'Data analytics', 'Architecting', 'Cosmos', 'SQL', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeRecruitment / Staffing,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
" Thanks & Best Regards,Hemalatha| Lead Talent Acquisition  www.cygnuspro.comCygnusPro Software Solutions Pvt. Ltd.Tel:     04068196805Mob:  9989759380email:  hemalatha@cygnuspro.com","RoleData warehouse Architect / Consultant,",Not Disclosed,15 - 20 years,Bangalore/Bengaluru,"Job description  Exp  15 + Yrs ,  Expertise in IICS Data Integration & App Integration                              Good Data Solutioning  Experience                              Exposure to Snowflake / Data Bricks                              Exposure to Java / Python will be added advantage                                Strong stakeholder management & Communication skills                              Exposure to Informatica EDC / Axon & MDMRoles and Responsibilities Desired Candidate Profile   Exp  15 + Yrs ,  Expertise in IICS Data Integration & App Integration                              Good Data Solutioning  Experience                              Exposure to Snowflake / Data Bricks                              Exposure to Java / Python will be added advantage                                Strong stakeholder management & Communication skills                              Exposure to Informatica EDC / Axon & MDMPerks and Benefits RoleData warehouse Architect / Consultant,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, Temporary/ContractualRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData SolutioningIICS Data Integration and App IntegrationInformatica EDC / Axon & MDMJava / PythonSnowflake / Data BricksSkills highlighted with ‘‘ are preferred keyskills","['Data Solutioning', 'IICS Data Integration and App Integration', 'Informatica EDC / Axon & MDM', 'Java / Python', 'Snowflake / Data Bricks']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Temporary/Contractual",Role CategoryDBA / Data warehousing
"Our Company is a guaranteed for its exceptional ELDF ( Enterprise Level Solution Development Firm ) for giving the particular services to different businesses with numerous physio-graphic puts over the world. We make the association for the intellectual business by working with up and coming latest advancements to serve the best client experience through customized benefits and upgraded collaboration.We are having a range of products like Customized ERP, Smart Dashboard, Audit, CRM and IOT.","RoleTechnical Architect,",Not Disclosed,8 - 15 years,Kolkata,"Job description     Good Understanding of Distributed Data Platforms.    Should have worked as data architect in Implementing a medium/large scale Data Warehouse solution.    Experience in Migrating Legacy Data Warehousing Solution to GCP Cloud.    Deep exposure hands-on GCP Cloud Native ETL / ELT services with deep understanding of BigQuery and Looker or any other reporting platform.    Possess in depth knowledge and hands on development experience operationalizing large scale ingestion, processing, consumption using either DataProc or Dataflow or cloud fusion.    Strong understanding and experience with Storage infrastructure, event-based architecture using Cloud Functions, Monitoring, Logging, Auditing services of GCP.    Strong experience on either one or more MPP Data Warehouse Platforms prefer BigQuery, CloudSQL, Cloud Spanner, Fire store or similar.    Strong Development Experience on at least one or more event-driven streaming platforms prefer PUB/SUB, Kafka   Exposure to Networking on GCP and Gateway connectivity.    Strong Data Orchestration experience using tools such has Cloud Functions, Dataflow, Cloud Composer, Apache Airflow or related.   RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsSUBorchestrationNetworkingGCPCloudData Architectcloud storageApacheData warehousingMonitoring","['SUB', 'orchestration', 'Networking', 'GCP', 'Cloud', 'Data Architect', 'cloud storage', 'Apache', 'Data warehousing', 'Monitoring']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"Triangle ( A Unit of Ratein Infotech India Private Ltd) is a Recruitment Specialist Organisation with focus on Information Technology Industry. Incorporated in August 2000 with 4 offices in India at Mumbai, Pune, New Delhi & Bangalore, Triangle caters to more than 25 active clients who are Fortune 500 organizations and world¢??s largest IT organizations.  Our Core expertise is in End to End Permanent and Contract Staffing and Extended Services.  We have been Internationally recognized as WeConnect Certified woman owned and managed organization.  Triangle has featured in CIO Review Magazine as ¢??Company of the Year in Staffing and Recruitment¢? Category for year 2014.","RoleTechnical Architect,",Not Disclosed,10 - 15 years,Bangalore/Bengaluru,"Job description    Azure Data Architect with streaming experience Job description Total experience in data management area for 10 + years with Azure cloud data platform experience Architect with Azure stack (ADLS, AALS, Azure Data Bricks, Azure Streaming Analytics Azure Data Factory, cosmos DB Azure synapse) mandatory expertise on Azure streaming Analytics ,Data Bricks, Azure synapse, Azure cosmos DB Must have worked experience in large Azure Data platform and dealt with high volume Azure streaming Analytics Experience in designing cloud data platform architecture, designing large scale environments 5 plus Years of experience architecting and building Cloud Data Lake, specifically Azure Data Analytics technologies and architecture is desired, Enterprise Analytics Solutions, and optimizing real time big data data pipelines, architectures and data sets     Job Description Architecting Microsoft Azure Solutions across multiple platforms    Implementation and Delivery of Microsoft Azure projects    Documentation of solutions (eg architecture, configuration and setup)    Working within a project management/agile delivery methodology in a leading role as part of a wider team    Experience of setting up, deploying and managing multiple environments to support agile development approaches hands-on experience with DevOps toolset    Knowledge of PowerShell, Git, ARM templates and deployment automation 10+ years of industry experience   Designing / Developing / Envisioning Enterprise apps using Azure IaaS and Analytics services with a focus on Azure RBAC, Azure AD, Azure Data Factory, Azure Data Lake Storage, Azure Function App, Azure Data Warehouse, Azure SQL DB, Azure Databricks      RoleTechnical Architect,Industry TypeRecruitment / Staffing,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateKey SkillsAutomationGITData managementPowershellProject managementAgile developmentData ArchitectArchitectural designCosmosSQL","['Automation', 'GIT', 'Data management', 'Powershell', 'Project management', 'Agile development', 'Data Architect', 'Architectural design', 'Cosmos', 'SQL']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeRecruitment / Staffing,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services — all powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. Our 674,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at accenture.com","RoleTechnical Architect,",Not Disclosed,12 - 15 years,Bangalore/Bengaluru,"Job description  Project Role :  Data Architect    Project Role Description :  Define the data requirements and structure for the application. Model and design the application data structure, storage and integration.    Management Level :  7    Work Experience :  12-15 years    Work location :  Bengaluru    Job Requirements :        Key Responsibilities :   1Function as the Lead Data Architect for a small, simple project/proposal or as a team lead for medium/large sized project or proposal2Discuss specific data architecture and data related issues with client architect/team in area of expertise3Analyze and assess the impact of the requirements on the data and its lifecycle4Lead the data architecture and design of complex, enterprise-level applications and systems5Breadth of experience in various client scenarios and situations     Technical Experience :   1Strong experience in Azure is preferred with hands-on experience in 2 or more of these skills : Azure SQL DB ,Azure SQL Managed Instance ,Azure Data Lake Store, Azure Cosmos DB, Azure Database for PostgreSQL, Azure Database for MySQL2Experience in handling medium to large data migration projects3 5 years of extensive database experience design build     Professional Attributes :   1Should be able to drive the technology design meetings, propose technology design and architecture 2Should have excellent client communication skills3Should have good analytical and problem-solving skills     Educational Qualification :   1Must have: BE/BTech/MCA 2Good to have: ME/MTech  RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :B.Tech/B.E.PG :MCA in Computers, M.TechKey SkillsData migrationPostgresqlMySQLConsultingSQLArchitectureAnalyticalCosmosData architectureSkills highlighted with ‘‘ are preferred keyskills","['Data migration', 'Postgresql', 'MySQL', 'Consulting', 'SQL', 'Architecture', 'Analytical', 'Cosmos', 'Data architecture']","['UG :B.Tech/B.E.', 'PG :MCA in Computers, M.Tech']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
Leading Client,"RoleTechnical Architect,",Not Disclosed,11 - 14 years,Bangalore/Bengaluru,"Job descriptionJob Description : Big Data Architect Function : Data Integration Location : Off Shore / India Basic Function : - The Big Data Architect works closely with the customer and the solutions architect to translate the customer's business requirements into a Big Data solution. - This includes understanding the customer data requirements, platform selection, design of the technical architecture, design of the application and interfaces, and development, testing, and deployment of the proposed solution. - Has the ability to design enterprise grade large-scale data processing systems and help identify the best options for architecture. - The Big Data Architect also understands the complexity of data and can design systems and models to handle different variety of data with varying levels of volume, velocity and veracity. - Should have independently worked on proposing architecture, design and data ingestion concepts in a consultative mode. - Leads client assessments, preparing current state and future state architectures along with go forward recommendations. - Will work with the practice leads and account management team to develop statements of work, implementation plans, resource plans and project estimates Essential Functions : - Has a deep understanding and experience with several of the following: Business Analysis, Requirements Gathering, Data Analysis, Data Modeling, Project Management, Project Estimation - Advanced knowledge of design and architecture patterns and methodologies. - Demonstrated work ethic, focus and self-discipline - Has and maintains a deep understanding of the role of big data in business and the enterprise. - Propose recommended and/or best practices regarding the movement, manipulation, and storage of data in a big data solution including data ingestion, data storage options, query techniques, data variety, volume & velocity, - Collaborate with project teams on platform development process from inception to production deployment, including project scheduling, design, implementation and coordination with other team members. - Collaborate with other technology teams and architects to define and develop cross- function technology stack interactions. - Research and experiment with emerging technologies and tools related to big data. - Experience in scaling applications on big data platforms to massive size. - Performing solution architecture in adherence to enterprise architecture governance. - Bridging business and development team. - Long term development and Technical expertise in DW/BI Practice, communicate well with all stakeholders, optimize objectives, leverage state of the art tools and best practices, integrate into corporate systems and deliver on time. - Deep understanding in Data Warehousing, Enterprise Architectures, Dimensional Modelling, Star & Snow-flake schema design, Reference DW Architectures, ETL Architect, ETL (Extract/Transform/Load), Data Analysis, Data Conversion/Transformation, Database Design, Data Warehouse Optimization, Data Mart Development, and Enterprise Data Warehouse Maintenance and Support etc. - Should have independently worked on proposing architecture, design and data ingestion concepts. Primary Internal Interactions : Project Delivery : - Formulates workable solutions that integrate people, process and technology. Integrates competency leads and other subject matter experts to define the details of vision and solution - Identifies, creates and communicates the vision of the end-to-end solution for the client and implementation teams after completing thorough evaluations of the present state needs - Leads technical teams in documenting and implementing technical solutions for business problems - Supports Delivery Enablement and Practice Leads by ensuring appropriate linkage between practices is clear and well understood - Works with practice leads to develop project estimating methodologies for new areas of focus Account & Resource Management : - Partners with the account teams to identify and sell solutions and create high level of client interest in proposed comprehensive solutions - Works closely with Engagement Managers, Account Managers and Account Leads in strategies to grow existing accounts - Partners with account team and client to develop the ROI, Business Case, and Statement of Work for an engagement - Develops comprehensive project, implementation, and resource plans working closely with Engagement and Project Managers Primary External Interactions : Assessment Participation & Leadership : - Identifies, creates and communicates the vision of the end-to-end solution for the client and implementation teams after completing thorough evaluations of the present state needs - Participates in strategy development and current state assessments for clients to identify opportunities. Acts as proxy for practice leads when necessary - Works with client to sell the proposed solution and develop internal marketing programs - Supports work that may not fall into an existing competency and helps to identify possible needs for new competencies. - Partners with account team and client to develop the ROI, Business Case, and Statement of Work for an engagement Organizational Relationships : Reports To : EDM India Practice Lead - over time, this will evolve Supervises : NA Skills : Technical Skills (Knowledge, Skills & Abilities) : - Experience with enterprise data management, Business Intelligence, data integration, and SQL database implementations - Experience with the major big data solutions like Hadoop, MapReduce, Hive, Spark, Scala, HBase, MongoDB, Cassandra. - Programming/scripting languages like Java, Linux, PHP, Ruby, Python and/or R. As well as have experience in working with ETL tools such as Informatica, Talend, Pentaho etc. - He or she should have experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms. - Experience in data migration from relational databases to Hadoop HDFS - Propose best practices/standards - Translate, load and present disparate datasets in multiple formats/sources including JSON, XML etc. Must Have Skills : - Hadoop stack including HDFS cluster, MapReduce, Hive, Spark and Impala - Web Technologies CSS, DHTML, XML, Hight Charts, Linux - ETL tools such as Informatica, Talend and/or Pentaho. Query : SQL, No SQL Concepts Ingest : Kafka, Sqoop, Flume Orchestration : Zookeeper Databases : Postgres, Mongo DB, Cassandra, HBase Languages : Java, Scala Scripting : JavaScript, DHTML, XML, Shell Good to have Skills : Core : AWS, Hadoop, Yarn Process : Agile-Scrum, Iterative Development, DevOps, CI Analytics : Descriptive, Predictive (Added advantage) Tools : Jenkins and TFS Languages : Python, Java Enterprise Process Specific Skills : (Supervisory Responsibilities) : - When the Bigdata Architect is acting as an engagement or project manager, they will be responsible for the overall supervision of the staff on the engagement.- They will be responsible for coaching and advising the team on the engagement. They will likely need to provide feedback to the people managers and practice leads of the resources on their engagement team. Soft skills (Desired) :- Experience working with multi-divisional business communities to leverage information across the enterprise to improve business effectiveness - Strong team building, interpersonal, analytical, problem identification and resolution skills Soft Skills (Minimum) : - Exceptional analytical, conceptual, and problem-solving abilities - Strong written/oral communication and presentation/interpersonal skills - Highly self-motivated and able to work independently as well as in a team environment Education Requirements : Bachelor's degree or Master's degree Work Experience Requirements : - Minimum 10 years of professional experience with BI/DW implementations and with at least 2-3 years of Big Data Architecture. - 3+ years of experience in technical or solution architecture providing large scale enterprise data solutions. RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :Any GraduatePG :Any PostgraduateDoctorate :Doctorate Not RequiredKey SkillsDatabase MaintenanceTechnical ArchitectBig Data ArchitectBusiness IntelligenceHadoopBig DataDatabase DesignData AnalystData WarehousingData ModelingMapReduceSkills highlighted with ‘‘ are preferred keyskills","['Database Maintenance', 'Technical Architect', 'Big Data Architect', 'Business Intelligence', 'Hadoop', 'Big Data', 'Database Design', 'Data Analyst', 'Data Warehousing', 'Data Modeling', 'MapReduce']","['UG :Any Graduate', 'PG :Any Postgraduate', 'Doctorate :Doctorate Not Required']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
"We Are Brillio. Born of the digital age in 2014. We are laser-focused on turning technological disruptions into the advantages that our customers need to thrive in todays digital economy.Brilliois a company focused on digital technologies andbig dataanalytics headquartered inSanta Clara, California, United States","RoleDatabase Architect / Designer,",Not Disclosed,6 - 10 years,Bangalore/Bengaluru,"Job description  BSc or MSc (preferred) in a STEM field Relevant work experience of 5 years Fluency in Python (especially Numpy and Pandas) and familiarity in PySpark Extensive hands-on experience with AWS Analytical Components like S3, EC2, Lambdas, Glue, SQS, SNS, DynamoDB, Redshift, RDS etc.    Experience with Data Lake Formation and Athena    Work Experience with industry standard distributed systems (ie    Spark, hive), data pipeline tools (ie    Airflow), NoSQL Databases (DynamoDB) and databases (PostgreSQL) Experience with Data Analysis, Significant experience optimizing data retrieval processes supporting API output, ideally within a low query volume / high data volume environment    Demonstrably deep experience with relevant big data processing either via Spark or through a modern MPP database like Redshift, ideally with experience in both Demonstrably deep experience with CI/CD tools and practices in a containerized AWS environment, from deployment pipelines (Jenkins, etc), infrastructure definition (Terraform, CloudFormation, etc    Understand and design for non-functional concerns such as performance, cost optimization, maintainability, and developer experience.             RoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData analysisNoSQLAnalyticalPostgresqlData ArchitectData processingbig dataDistribution systemCost optimizationPython","['Data analysis', 'NoSQL', 'Analytical', 'Postgresql', 'Data Architect', 'Data processing', 'big data', 'Distribution system', 'Cost optimization', 'Python']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Coforge is a leading global IT solutions organization, enabling its clients to transform at the intersect of unparalleled domain expertise and emerging technologies to achieve real-world business impact. A focus on very select industries, a detailed understanding of the underlying processes of those industries, and partnerships with leading platforms provide us a distinct vantage. We leverage AI, Cloud, and Insight-driven technologies, allied with our industry expertise, to transform client businesses into intelligent, high growth enterprises. Today our proprietary platforms power critical business processes across the Financial Services and Travel industries. Our 23,500 technology and process consultants engineer, design, consult, operate, and modernize systems across the world. Coforge is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity, or any other basis as protected by applicable law.","RoleData warehouse Architect / Consultant,",Not Disclosed,10 - 15 years,Noida,"Job descriptionData Architect:  At least 10 years of professional data modeling experience.  Expert in Data modeling:  •	Data Vault 2.0 •	Dimensional modelling •	3NF modelling Business requirement:  •	Ability to engage with business stakeholders •	Structure approach to Business requirement gathering •	Ability to break down business requirement into KPI’s, Dimensions and Facts ETL architecture Data warehousing patterns (Kimball/Inmon) Knowledge of data modelling tools i.e. SAP Powerdesigner, Wherescape 3D, Erwin Knowledge of SQL Power BI knowledge (nice to have) Snowflake/ AWS knowledge (nice to have) Please share resumes on priyata.singh@coforge.comRoleData warehouse Architect / Consultant,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateDoctorate :Any DoctorateKey SkillsData ModelingData VaultData ArchitectureSkills highlighted with ‘‘ are preferred keyskills","['Data Modeling', 'Data Vault', 'Data Architecture']","['UG :Any Graduate', 'PG :Any Postgraduate', 'Doctorate :Any Doctorate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
Leading Client,"RoleDatabase Architect / Designer,",Not Disclosed,3 - 8 years,Bangalore/Bengaluru,"Job description- Create and maintain optimal data pipeline architecture- Assemble large complex data sets that meet functional business requirements- Identify, design, and implement internal process improvements- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other data technologies- Build analytical tools that utilize the data pipeline to provide actionable insight into customer acquisition, operational efficiency, and other key business performance metricsPeople should have :- Master's or Bachelor's degree in computer science or information technology- Extensive knowledge about various programming languages- Technical expertise with data models, data mining, and segmentation techniques- Experience with SQL database design- Creative problem solving and strong communication skills- Strong numerical and analytical skills with the demonstrated ability to research and make decisions based on the day-to-day and complex customer problems requiredRoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :BCA in ComputersPG :MCA in ComputersDoctorate :Doctorate Not RequiredKey SkillsData PipelineData MiningPythonJavaData ModelingSQLSkills highlighted with ‘‘ are preferred keyskills","['Data Pipeline', 'Data Mining', 'Python', 'Java', 'Data Modeling', 'SQL']","['UG :BCA in Computers', 'PG :MCA in Computers', 'Doctorate :Doctorate Not Required']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
ASPIRE SYSTEMS,"RoleDatabase Architect / Designer,","₹ 17,00,000 - 30,00,000 P.A. ",12 - 15 years,Chennai,"Job descriptionRoles and Responsibilities  Expertise in understanding the Functional Requirements and do the modelling of DWH Expertise in understanding the Data integration across the landscape Expertise in designing ETL packages. Expertise in job scheduling, debugging, enhancement of ETL jobs Expertise in Designing DWH, STAR schema, SNOWFLAKE schema Good knowledge in creating stored procedures and functions Good Knowledge in Performance tuning of SSIS, Tsql queries Should handle large volume of data sync using any ETL tool Understanding of non-functional requirements Should be proficient in understanding DWH, mpp systems, OLTP, and OLAP systems. Should document the code and functional changes A good team player and excellent communicator   AWS Architect (ETL and Data Architect) Years of Experience : 12 years and above Location : Chennai/Bangalore Onsite option available - Dubai Interview : Two technical rounds of interview Tools and Skills : Apache airflow, MySQL,AWS GLUE, POSTGRES , TALEND AND ANY DATA MODELLING TOOLS , REDSHIFTS, POSTGRES.RoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduateKey SkillsApache AirflowArchitectureAWS gluePostgresAWSsql server any of these DatabasesMysqlTalend and any data modelling tools.  RedshiftSkills highlighted with ‘‘ are preferred keyskills","['Apache Airflow', 'Architecture', 'AWS glue', 'Postgres', 'AWS', 'sql server any of these Databases', 'Mysql', 'Talend and any data modelling tools.  Redshift']",['UG :Any Graduate'],"Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Founded in 1976, CGI is among the largest IT and business consulting services firms in the world. Operating in hundreds of locations across the globe, CGI delivers end-to-end services and solutions, including strategic IT and business consulting, systems integration, intellectual property, and managed IT and business process services","RoleDatabase Architect / Designer,",Not Disclosed,3 - 8 years,Bangalore/Bengaluru,"Job descriptionPosition Description:Act as the primary point of contact within the organization for members of staff, regulators, and any relevant public bodies on issues related to data protectionEnsure the company’s policy is in accordance with General Data Protection Regulation (GDPR) and codes of practiceEvaluate the existing data protection framework and identify areas of non or partial compliance and rectify any issuesDevise training plans and provide data protection advice and support for members of staffInform and advise the Data Controller or Data Processor on all matters related to data protectionPromote a culture of data protection compliance across all units of the organizationDaily and Monthly ResponsibilitiesProvide expert advice and educate employees on important data compliance requirementsDraft new and amend existing internal data protection policies, guidelines, and procedures, in consultation with key stakeholdersHold training with staff members across different business units who are involved in data handling or processingProactively conduct audits to ensure compliance and address potential issuesMaintain records of all data processing activities carried out by the companyServe as the point of contact between the company and the data protection authoritiesMinimum of three years experience working in data protection compliance or a related fieldExpertise in European data protection laws and practices including an in-depth understanding of the GDPRExperience within a legal, audit and/or risk function departmentAbility to manage sensitive and confidential informationOwn and keep under constant review all the organization’s global data protection compliance arrangements to include updating policies and guidance, centralising processes and putting in place robust, time-bound remedial plans where necessary.Develop and maintain relevant global internal data privacy policies and training.Inform and advise the global organization on the Global Data Protection Regulation (GDPR) and its requirements, liaising with local support as required. Serving as a subject matter expert and developing and implementing a robust compliance plan.Partner with all key business areas, in particular the IT Security team, to ensure data privacy issues are considered at the outset of new projects, products and initiatives Act as a liaison between onshore and offshore teams in relation to global data privacy issues.Help manage the data privacy network across all global offices.Handle enquiries and issues relating to data privacy practices, withdrawal of consent, the right to be forgotten, and related rights.Monitor the industry landscape to keep visibility on evolutions, trends, and best practices related to Data PrivacyEnsure that systematic compliance audits are undertaken and that their findings are reported and acted upon.Demonstrate deep knowledge of data privacy, data handling and data classification.Demonstrate experience of managing data privacy issues in a global organisation.Expertise in global and European data protection laws and practices and an in-depth understanding of the GDPR.Capable of conducting data privacy compliance reviews and audits.Have the ability to develop awareness and communications at all levels within the organizationAbility to review, analyse and organise documentary and factual evidence. Skills:Data ArchitectureRoleDatabase Architect / Designer,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategoryDBA / Data warehousingEducationUG :Any GraduatePG :Any PostgraduateKey SkillsData Privacyaudit complianceit securitydata managementhp data protectordata classificationdata processingSkills highlighted with ‘‘ are preferred keyskills","['Data Privacy', 'audit compliance', 'it security', 'data management', 'hp data protector', 'data classification', 'data processing']","['UG :Any Graduate', 'PG :Any Postgraduate']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategoryDBA / Data warehousing
"Accenture is a global professional services company with leading capabilities in digital, cloud and security. Combining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Interactive, Technology and Operations services — all powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. Our 674,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. We embrace the power of change to create value and shared success for our clients, people, shareholders, partners and communities. Visit us at accenture.com","RoleTechnical Architect,",Not Disclosed,6 - 8 years,Bangalore/Bengaluru,"Job description  Project Role :  Data Architect    Project Role Description :  Define the data requirements and structure for the application. Model and design the application data structure, storage and integration.    Management Level :  9    Work Experience :  6-8 years    Work location :  Bengaluru    Job Requirements :        Key Responsibilities :   aFunction as the Lead Data Architect for a small, simple project/proposal or as a team lead for medium/large sized project or proposalbDiscuss specific Big data architecture and related issues with client architect/team in area of expertisecAnalyze and assess the impact of the requirements on the data and its lifecycledLead Big data architecture and design medium-big Cloud based, Big Data and Analytical Solutions using Lambda architectureeBreadth of experience in various client scenario     Technical Experience :   aStrong experience in Azure is preferred with hands-on experience in two or more of these skills : Azure Synapse Analytics, Azure HDInsight, Azure Databricks with PySpark / Scala / SparkSQL, Azure Analysis ServicesbExperience in one or more Real-time/Streaming technologies including: Azure Stream Analytics, Azure Data Explorer, Azure Time Series Insights, etccExperience in handling medium to large Big Data implementationsdFor Level 8 - Candidate must have 10-12 years of IT experience     Professional Attributes :   aShould be able to drive the technology design meetings, propose technology design and architecture bShould have excellent client communication skillscShould have good analytical and problem-solving skills     Educational Qualification :   aMust have: BE/Btech/MCA bGood to have: ME/Mtech  RoleTechnical Architect,Industry TypeIT Services & Consulting,Functional AreaEngineering - Software & QA,Employment TypeFull Time, PermanentRole CategorySoftware DevelopmentEducationUG :B.Tech/B.E.PG :MCA in Computers, M.TechKey SkillsAnalyticalConsultingSCALAAnalyticsData architectureArchitecturebig dataSkills highlighted with ‘‘ are preferred keyskills","['Analytical', 'Consulting', 'SCALA', 'Analytics', 'Data architecture', 'Architecture', 'big data']","['UG :B.Tech/B.E.', 'PG :MCA in Computers, M.Tech']","Industry TypeIT Services & Consulting,","Functional AreaEngineering - Software & QA,","Employment TypeFull Time, Permanent",Role CategorySoftware Development
